{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Import libraries**","metadata":{"id":"peGjbYAXpGT7"}},{"cell_type":"code","source":"import numpy as np \nfrom tqdm import tqdm\nimport cv2\nimport os\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nimport itertools\nimport plotly.graph_objs as go\nfrom plotly.offline import init_notebook_mode, iplot\nfrom plotly import tools\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.vgg16 import VGG16, preprocess_input\nfrom keras import layers\nfrom keras.models import Model, Sequential\nfrom keras.optimizers import Adam, RMSprop\nfrom keras.callbacks import EarlyStopping\nfrom keras.preprocessing.image import ImageDataGenerator\ninit_notebook_mode(connected=True)\nRANDOM_SEED = 123","metadata":{"id":"vENXbhH6Bo6J","outputId":"580f7923-4120-432f-9a1d-e85422e86023","execution":{"iopub.status.busy":"2022-08-03T21:12:47.447982Z","iopub.execute_input":"2022-08-03T21:12:47.448325Z","iopub.status.idle":"2022-08-03T21:12:48.367217Z","shell.execute_reply.started":"2022-08-03T21:12:47.448295Z","shell.execute_reply":"2022-08-03T21:12:48.366310Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"Helper functions","metadata":{}},{"cell_type":"code","source":"def load_data(dir_path, IMG_SIZE):\n   \n    X = []\n    y = []\n    i = 0\n    labels = dict()\n    for path in tqdm(sorted(os.listdir(dir_path))):\n        if not path.startswith('.'):\n            labels[i] = path\n            for file in os.listdir(dir_path + path):\n                if not file.startswith('.'):\n                    img = cv2.imread(dir_path + path + '/' + file)\n                    img = img.astype('float32') / 255\n                    resized = cv2.resize(img, IMG_SIZE, interpolation = cv2.INTER_AREA)\n                    X.append(resized)\n                    y.append(i)\n            i += 1\n    X = np.array(X)\n    y = np.array(y)\n    print(f'{len(X)} images loaded from {dir_path} directory.')\n    return X, y, labels\n\ndef plot_samples(X, y, labels_dict, n=50):\n   \n    for index in range(len(labels_dict)):\n        imgs = X[np.argwhere(y == index)][:n]\n        j = 10\n        i = int(n/j)\n\n        plt.figure(figsize=(10,3))\n        c = 1\n        for img in imgs:\n            plt.subplot(i,j,c)\n            plt.imshow(img[0])\n\n            plt.xticks([])\n            plt.yticks([])\n            c += 1\n        plt.suptitle(labels_dict[index])\n        plt.show()\n\ndef deep_model(model, X_train, Y_train, epochs, batch_size, validation_data=None):\n   \n    model.compile(\n    loss='binary_crossentropy',\n    optimizer=RMSprop(learning_rate=1e-4),\n    metrics=['accuracy'])\n    \n    history = model.fit(X_train\n                       , Y_train\n                       , epochs=epochs\n                       , batch_size=batch_size\n                       , verbose=1\n                       , validation_data=validation_data)\n    return history","metadata":{"execution":{"iopub.status.busy":"2022-08-03T21:12:48.370189Z","iopub.execute_input":"2022-08-03T21:12:48.370454Z","iopub.status.idle":"2022-08-03T21:12:48.381500Z","shell.execute_reply.started":"2022-08-03T21:12:48.370427Z","shell.execute_reply":"2022-08-03T21:12:48.380535Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# **Load Data and Plot Samples**","metadata":{"id":"mLXfHj8LpPOC"}},{"cell_type":"code","source":"TRAIN_DIR = ('../input/facial-recognition-dataset/Training/Training/')\nTEST_DIR = ('../input/facial-recognition-dataset/Testing/Testing/')\nTEST_DIR_BIAS = ('../input/possiblybiasedfaces/possible-bias/')\n\nIMG_SIZE= (48, 48)\n\nX_train, y_train, train_labels = load_data(TRAIN_DIR, IMG_SIZE)\n\nX_test, y_test, test_labels = load_data(TEST_DIR,IMG_SIZE)\n\nX_test_bias, y_test_bias, test_labels = load_data(TEST_DIR_BIAS,IMG_SIZE)\n\n\ntrain_labels","metadata":{"id":"hytHM7rYYXv9","execution":{"iopub.status.busy":"2022-08-03T21:12:48.383101Z","iopub.execute_input":"2022-08-03T21:12:48.383663Z","iopub.status.idle":"2022-08-03T21:16:31.888234Z","shell.execute_reply.started":"2022-08-03T21:12:48.383627Z","shell.execute_reply":"2022-08-03T21:16:31.887343Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"plot_samples(X_test_bias, y_test_bias, train_labels, 10)","metadata":{"execution":{"iopub.status.busy":"2022-08-03T21:16:31.890034Z","iopub.execute_input":"2022-08-03T21:16:31.890712Z","iopub.status.idle":"2022-08-03T21:16:34.332677Z","shell.execute_reply.started":"2022-08-03T21:16:31.890662Z","shell.execute_reply":"2022-08-03T21:16:34.331877Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"plot_samples(X_train, y_train, train_labels, 10)","metadata":{"id":"DD2D3PjFdBwL","outputId":"cef69d10-d044-4d88-c86e-f74799f6fdac","execution":{"iopub.status.busy":"2022-08-03T21:16:34.337593Z","iopub.execute_input":"2022-08-03T21:16:34.339627Z","iopub.status.idle":"2022-08-03T21:16:36.789418Z","shell.execute_reply.started":"2022-08-03T21:16:34.339587Z","shell.execute_reply":"2022-08-03T21:16:36.788395Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from keras.utils.np_utils import to_categorical\n\nY_train = to_categorical(y_train, num_classes=6)\nY_test = to_categorical(y_test, num_classes=6)\nY_test_bias = to_categorical(y_test_bias, num_classes=6)\n\nprint(Y_train.shape)\nprint(Y_test.shape)\nprint(Y_test_bias.shape)","metadata":{"id":"MQmK5-gjWgE3","outputId":"0e3a377e-6e90-417b-e18e-4133d822770d","execution":{"iopub.status.busy":"2022-08-03T21:16:36.791026Z","iopub.execute_input":"2022-08-03T21:16:36.791407Z","iopub.status.idle":"2022-08-03T21:16:36.801030Z","shell.execute_reply.started":"2022-08-03T21:16:36.791369Z","shell.execute_reply":"2022-08-03T21:16:36.799987Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications import VGG19\n\nbase_model = VGG19(\n    include_top=False,\n    weights=None,\n    input_tensor=None,\n    input_shape=IMG_SIZE + (3,),\n    pooling=None,\n    classes=1000\n)\n\nNUM_CLASSES = 6\n\nmodel = Sequential()\nmodel.add(base_model)\nmodel.add(Flatten())\nmodel.add(Dense(1000, activation=\"relu\"))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(NUM_CLASSES, activation=\"softmax\"))\n\nbase_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-08-03T21:16:36.802800Z","iopub.execute_input":"2022-08-03T21:16:36.803194Z","iopub.status.idle":"2022-08-03T21:16:38.939547Z","shell.execute_reply.started":"2022-08-03T21:16:36.803156Z","shell.execute_reply":"2022-08-03T21:16:38.938768Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"epochs = 35\nbatch_size = 64\n\nhistory = deep_model(model, X_train, Y_train, epochs, batch_size, validation_data=(X_test, Y_test))","metadata":{"id":"WA7MYEhugrdN","outputId":"bb6719c5-e2ce-472b-84d1-b0b684bfd6c8","execution":{"iopub.status.busy":"2022-08-03T16:26:43.347525Z","iopub.execute_input":"2022-08-03T16:26:43.347990Z","iopub.status.idle":"2022-08-03T16:39:07.309198Z","shell.execute_reply.started":"2022-08-03T16:26:43.347928Z","shell.execute_reply":"2022-08-03T16:39:07.307800Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"**Confusion Matrix**\n\nAdditionally, the sensitivity, specificity, F-score, and accuracy are calculated for each class by using the following calculated confusion matrix Fig for the six classes for emotion detection. Each class is used against all classes in order to find those performance factors related to it.\n\n","metadata":{"id":"GDgz0DsqrkLh"}},{"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \n    plt.figure(figsize = (6,6))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    cm = np.round(cm,2)\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()","metadata":{"id":"A5XAbK0qPDhI","execution":{"iopub.status.busy":"2022-08-03T16:39:07.311192Z","iopub.execute_input":"2022-08-03T16:39:07.311509Z","iopub.status.idle":"2022-08-03T16:39:07.320894Z","shell.execute_reply.started":"2022-08-03T16:39:07.311480Z","shell.execute_reply":"2022-08-03T16:39:07.319459Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Validate on test set\n\npredictions = model.predict(X_test)\npredictions_bias = model.predict(X_test_bias)\n\ny_pred = [np.argmax(probas) for probas in predictions]\ny_pred_bias = [np.argmax(probas) for probas in predictions_bias]\n\n\naccuracy = accuracy_score(y_test, y_pred)\nprint('Test Accuracy = %.2f' % accuracy)\naccuracy_bias = accuracy_score(y_test_bias, y_pred_bias)\nprint('Test Accuracy Bias = %.2f' % accuracy)\n\nconfusion_mtx = confusion_matrix(y_test, y_pred) \ncm = plot_confusion_matrix(confusion_mtx, classes = list(test_labels.items()), normalize=False)\n\n\nconfusion_mtx_bias = confusion_matrix(y_test_bias, y_pred_bias) \ncm_bias = plot_confusion_matrix(confusion_mtx_bias, classes = list(test_labels.items()), normalize=False)","metadata":{"id":"DAIf2z4GPG3E","outputId":"c3ddbd10-f38c-4cd5-f0a0-3e8dd25eaac3","execution":{"iopub.status.busy":"2022-08-03T16:39:07.323874Z","iopub.execute_input":"2022-08-03T16:39:07.324717Z","iopub.status.idle":"2022-08-03T16:39:10.575460Z","shell.execute_reply.started":"2022-08-03T16:39:07.324675Z","shell.execute_reply":"2022-08-03T16:39:10.574312Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"**Let's try our model and make predictions**","metadata":{"id":"x6FVGSAAtQ2D"}},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\ndatagen_test = ImageDataGenerator(rescale = 1./255)\npred_generator = datagen_test.flow_from_directory(TEST_DIR,\n                                                 target_size = (48,48),\n                                                 color_mode = \"grayscale\",\n                                                 batch_size = batch_size,\n                                                 class_mode = \"categorical\",\n                                                 shuffle=False)","metadata":{"id":"gTTvpA-ly98w","outputId":"ab9ebaec-397c-4553-9bc1-44b12ad300de","execution":{"iopub.status.busy":"2022-08-03T15:47:31.805244Z","iopub.status.idle":"2022-08-03T15:47:31.806295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_predictions = model.predict(X_test)\ny_pred = [np.argmax(probas) for probas in new_predictions]\ny_pred = [test_labels[k] for k in y_pred]","metadata":{"id":"JqgnC66Jzsad","execution":{"iopub.status.busy":"2022-08-03T15:47:31.807824Z","iopub.status.idle":"2022-08-03T15:47:31.808844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filenames = pred_generator.filenames\nactual_class = [test_labels[h] for h in pred_generator.classes]","metadata":{"id":"j0U9RhDs0K5B","execution":{"iopub.status.busy":"2022-08-03T15:47:31.810319Z","iopub.status.idle":"2022-08-03T15:47:31.811411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\npred_result = pd.DataFrame({\"Filename\":filenames,\n                           \"Predictions\":y_pred,\n                           \"Actual Values\":actual_class})\n\npred_result.head()","metadata":{"id":"xAm_xJ4f0bSM","outputId":"9a14cf15-dd34-4095-a6bc-680e00c6c533","execution":{"iopub.status.busy":"2022-08-03T15:47:31.812979Z","iopub.status.idle":"2022-08-03T15:47:31.814037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from random import randint\n\nl = len(filenames)\nbase_path = TEST_DIR\nfor i in range(10):  # 10 images\n    \n    rnd_number = randint(0,l-1)\n    filename,pred_class,actual_class = pred_result.loc[rnd_number]\n    \n    img_path = os.path.join(base_path,filename)\n    img = cv2.imread(img_path)\n    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n    plt.imshow(img)\n    plt.title(\"Predicted Class: {} {} Actual Class: {}\".format(pred_class,'\\n',actual_class))\n    plt.show()\n    pass","metadata":{"id":"ggZVCbRX0qQ0","outputId":"44cb2e0c-7045-4390-9648-3189e256fe65","execution":{"iopub.status.busy":"2022-08-03T15:47:31.815532Z","iopub.status.idle":"2022-08-03T15:47:31.816520Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}